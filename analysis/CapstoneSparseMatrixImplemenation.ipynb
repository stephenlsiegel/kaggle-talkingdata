{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "datadir = \"../data/final-data-files/\"\n",
    "\n",
    "ga_train = pd.read_csv(os.path.join(datadir, 'ga_train_final.csv'), index_col='device_id_enc')\n",
    "ga_test = pd.read_csv(os.path.join(datadir, 'ga_test_final.csv'), index_col='device_id_enc')\n",
    "\n",
    "pbdm = pd.read_csv(os.path.join(datadir, 'pbdm_final.csv'), index_col='device_id_enc')\n",
    "\n",
    "app_id_sparse = pd.read_csv(os.path.join(datadir, 'app-data-sparse', 'app_id_sparse.csv'))\n",
    "\n",
    "app_id_active_sparse = pd.read_csv(os.path.join(datadir, 'app-data-sparse', 'app_id_active_sparse.csv'))\n",
    "\n",
    "category_sparse = pd.read_csv(os.path.join(datadir, 'app-data-sparse', 'category_sparse.csv'))\n",
    "\n",
    "category_active_sparse = pd.read_csv(os.path.join(datadir, 'app-data-sparse', 'category_active_sparse.csv'))\n",
    "\n",
    "app_id_encoder = pd.read_csv(os.path.join('../data/processed/app_id_encoder.csv'))\n",
    "category_encoder = pd.read_csv(os.path.join('../data/processed/category_encoder.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add row numbers to ga_train\n",
    "ga_train['train_row'] = np.arange(ga_train.shape[0])\n",
    "ga_train['test_row'] = -1\n",
    "\n",
    "# Add row numbers to ga_test\n",
    "ga_test['train_row'] = -1\n",
    "ga_test['test_row'] = np.arange(ga_test.shape[0])\n",
    "\n",
    "# Create all_devices table that combines ga_train and ga_test so we can do preprocessing for both at the same time\n",
    "all_devices = pd.concat([(ga_train[['train_row', 'test_row']]), ga_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge all devices into each sparse table to add row numbers to sparse table\n",
    "# Also separate into train and test\n",
    "app_id_sparse = app_id_sparse.merge(all_devices, how='left', left_on='device_id_enc', right_index=True)\n",
    "app_id_sparse_train = app_id_sparse[app_id_sparse['train_row']>=0]\n",
    "app_id_sparse_test = app_id_sparse[app_id_sparse['test_row']>=0]\n",
    "\n",
    "app_id_active_sparse = app_id_active_sparse.merge(all_devices, how='left', left_on='device_id_enc', right_index=True)\n",
    "app_id_active_sparse_train = app_id_active_sparse[app_id_active_sparse['train_row']>=0]\n",
    "app_id_active_sparse_test = app_id_active_sparse[app_id_active_sparse['test_row']>=0]\n",
    "\n",
    "category_sparse = category_sparse.merge(all_devices, how='left', left_on='device_id_enc', right_index=True)\n",
    "category_sparse_train = category_sparse[category_sparse['train_row']>=0]\n",
    "category_sparse_test = category_sparse[category_sparse['test_row']>=0]\n",
    "\n",
    "category_active_sparse = category_active_sparse.merge(all_devices, how='left', left_on='device_id_enc', right_index=True)\n",
    "category_active_sparse_train = category_active_sparse[category_active_sparse['train_row']>=0]\n",
    "category_active_sparse_test = category_active_sparse[category_active_sparse['test_row']>=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sparse Matrix for PBDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create sparse matrix for PBDM\n",
    "\n",
    "# First merge in pbdm\n",
    "all_devices_pbdm = all_devices.merge(pbdm, how='left', left_index=True, right_index=True)[['train_row', 'test_row', 'phone_brand_enc', 'device_model_enc']]\n",
    "\n",
    "# Separate into train and test\n",
    "pbdm_train = all_devices_pbdm[all_devices_pbdm['train_row']>=0]\n",
    "pbdm_test = all_devices_pbdm[all_devices_pbdm['test_row']>=0]\n",
    "\n",
    "# Sparse matrix on phone brand for train and test\n",
    "Xtrain_pb = csr_matrix((np.ones(pbdm_train.shape[0]), (pbdm_train.train_row, pbdm_train.phone_brand_enc)))\n",
    "Xtest_pb = csr_matrix((np.ones(pbdm_test.shape[0]), (pbdm_test.test_row, pbdm_test.phone_brand_enc)))\n",
    "\n",
    "# Sparse matrix on device model for train and test\n",
    "Xtrain_dm = csr_matrix((np.ones(pbdm_train.shape[0]), (pbdm_train.train_row, pbdm_train.device_model_enc)))\n",
    "Xtest_dm = csr_matrix((np.ones(pbdm_test.shape[0]), (pbdm_test.test_row, pbdm_test.device_model_enc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sparse Matrix for App ID and Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sparse matrix on app ID for train and test\n",
    "Xtrain_appid = csr_matrix((np.ones(app_id_sparse_train.shape[0]),\n",
    "                           (app_id_sparse_train.train_row, app_id_sparse_train.app_id_enc)),\n",
    "                          shape=(ga_train.shape[0],app_id_encoder.shape[0]+1))\n",
    "\n",
    "Xtest_appid = csr_matrix((np.ones(app_id_sparse_test.shape[0]),\n",
    "                         (app_id_sparse_test.test_row, app_id_sparse_test.app_id_enc)),\n",
    "                        shape=(ga_test.shape[0],app_id_encoder.shape[0]+1))\n",
    "\n",
    "# Sparse matrix on app ID active for train and test\n",
    "Xtrain_appida = csr_matrix((np.ones(app_id_active_sparse_train.shape[0]),\n",
    "                               (app_id_active_sparse_train.train_row, app_id_active_sparse_train.app_id_enc)),\n",
    "                              shape=(ga_train.shape[0],app_id_encoder.shape[0]+1))\n",
    "\n",
    "Xtest_appida = csr_matrix((np.ones(app_id_active_sparse_test.shape[0]),\n",
    "                               (app_id_active_sparse_test.test_row, app_id_active_sparse_test.app_id_enc)),\n",
    "                              shape=(ga_test.shape[0],app_id_encoder.shape[0]+1))\n",
    "\n",
    "# Sparse matrix on category for train and test\n",
    "Xtrain_category = csr_matrix((np.ones(category_sparse_train.shape[0]),\n",
    "                               (category_sparse_train.train_row, category_sparse_train.category_enc)),\n",
    "                              shape=(ga_train.shape[0],category_encoder.shape[0]+1))\n",
    "\n",
    "Xtest_category = csr_matrix((np.ones(category_sparse_test.shape[0]),\n",
    "                               (category_sparse_test.test_row, category_sparse_test.category_enc)),\n",
    "                              shape=(ga_test.shape[0],category_encoder.shape[0]+1))\n",
    "\n",
    "# Sparse matrix on category active for train and test\n",
    "Xtrain_categorya = csr_matrix((np.ones(category_active_sparse_train.shape[0]),\n",
    "                               (category_active_sparse_train.train_row, category_active_sparse_train.category_enc)),\n",
    "                              shape=(ga_train.shape[0],category_encoder.shape[0]+1))\n",
    "\n",
    "Xtest_categorya = csr_matrix((np.ones(category_active_sparse_test.shape[0]),\n",
    "                               (category_active_sparse_test.test_row, category_active_sparse_test.category_enc)),\n",
    "                              shape=(ga_test.shape[0],category_encoder.shape[0]+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine all sparse matrices\n",
    "Xtrain = hstack((Xtrain_pb, Xtrain_dm, Xtrain_appid, Xtrain_appida, Xtrain_category, Xtrain_categorya), format='csr')\n",
    "Xtest = hstack((Xtest_pb, Xtest_dm, Xtest_appid, Xtest_appida, Xtest_category, Xtest_categorya), format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get labels\n",
    "y = ga_train['group_enc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run through Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "features = Xtrain\n",
    "labels = y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=1)\n",
    "\n",
    "clf_device = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "clf_device.fit(X_train, y_train)\n",
    "\n",
    "pred_device = clf_device.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4899718663128869"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(np.array(y_test), pred_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2.0, 2.5246550834140598), (1.0, 2.4899718663128869), (0.5, 2.4164753734715827), (0.1, 2.3378787435612702), (0.05, 2.3030158056680095), (0.01, 2.2825095875909676), (0.005, 2.2897505389247894), (0.001, 2.328692771053285)]\n"
     ]
    }
   ],
   "source": [
    "# Tune C value\n",
    "c_tuning = [2.0, 1.0, 0.5, 0.1, 0.05, 0.01, 0.005, 0.001]\n",
    "log_loss_scores = []\n",
    "\n",
    "for C in c_tuning:\n",
    "    clf_tuning = LogisticRegression(C=C, multi_class='multinomial', solver='lbfgs')\n",
    "    clf_tuning.fit(X_train, y_train)\n",
    "    pred = clf_tuning.predict_proba(X_test)\n",
    "    ll = log_loss(np.array(y_test), pred)\n",
    "    log_loss_scores.append((C, ll))\n",
    "print log_loss_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.05, 2.3030158056680095), (0.0455, 2.2994875644892621), (0.041, 2.2968234409285855), (0.0365, 2.2929992064314773), (0.032, 2.2897877637158279), (0.0275, 2.2866937547402197), (0.023, 2.2841777107477941), (0.0185, 2.2822195464368908), (0.014, 2.2815639930697595), (0.0095, 2.2827292396446244), (0.005, 2.2897505389247894)]\n"
     ]
    }
   ],
   "source": [
    "# Tune C further, focusing on 0.05 to 0.005\n",
    "c_tuning = [0.05,0.0455,0.041,0.0365,0.032,0.0275,0.023,0.0185,0.014,0.0095,0.005]\n",
    "log_loss_scores = []\n",
    "\n",
    "for C in c_tuning:\n",
    "    clf_tuning = LogisticRegression(C=C, multi_class='multinomial', solver='lbfgs')\n",
    "    clf_tuning.fit(X_train, y_train)\n",
    "    pred = clf_tuning.predict_proba(X_test)\n",
    "    ll = log_loss(np.array(y_test), pred)\n",
    "    log_loss_scores.append((C, ll))\n",
    "print log_loss_scores\n",
    "# best score: c=0.014, logloss=2.2815639930697595"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0167, 2.2819129653591976), (0.0149, 2.2815105672255389), (0.0131, 2.2815849324156479), (0.0113, 2.2819902982359586)]\n"
     ]
    }
   ],
   "source": [
    "# Final C tuning\n",
    "c_tuning = [0.0167,0.0149,0.0131,0.0113]\n",
    "log_loss_scores = []\n",
    "\n",
    "for C in c_tuning:\n",
    "    clf_tuning = LogisticRegression(C=C, multi_class='multinomial', solver='lbfgs')\n",
    "    clf_tuning.fit(X_train, y_train)\n",
    "    pred = clf_tuning.predict_proba(X_test)\n",
    "    ll = log_loss(np.array(y_test), pred)\n",
    "    log_loss_scores.append((C, ll))\n",
    "print log_loss_scores\n",
    "# best score: c=0.0149, logloss=2.2815105672255389"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use C = 0.0149, output encoded submission file\n",
    "clf = LogisticRegression(C=0.0149, multi_class='multinomial', solver='lbfgs')\n",
    "clf.fit(Xtrain, y)\n",
    "pred_test = clf.predict_proba(Xtest)\n",
    "pred_test = pd.DataFrame(pred_test, index=ga_test.index)\n",
    "\n",
    "# Write to csv\n",
    "pred_test.to_csv('../submissions/encoded/prediction-0149.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Model Evaluation and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>41124.000000</td>\n",
       "      <td>41124.000000</td>\n",
       "      <td>41124.000000</td>\n",
       "      <td>41124.000000</td>\n",
       "      <td>41124.000000</td>\n",
       "      <td>41124.000000</td>\n",
       "      <td>41124.000000</td>\n",
       "      <td>41124.000000</td>\n",
       "      <td>41124.000000</td>\n",
       "      <td>41124.000000</td>\n",
       "      <td>41124.000000</td>\n",
       "      <td>41124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000223</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>-0.000182</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.015302</td>\n",
       "      <td>0.012878</td>\n",
       "      <td>0.011970</td>\n",
       "      <td>0.013568</td>\n",
       "      <td>0.015274</td>\n",
       "      <td>0.014069</td>\n",
       "      <td>0.017283</td>\n",
       "      <td>0.016889</td>\n",
       "      <td>0.014073</td>\n",
       "      <td>0.015388</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.018429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.279700</td>\n",
       "      <td>-0.239281</td>\n",
       "      <td>-0.168041</td>\n",
       "      <td>-0.231304</td>\n",
       "      <td>-0.296560</td>\n",
       "      <td>-0.323304</td>\n",
       "      <td>-0.440936</td>\n",
       "      <td>-0.284944</td>\n",
       "      <td>-0.228971</td>\n",
       "      <td>-0.336297</td>\n",
       "      <td>-0.351654</td>\n",
       "      <td>-0.439251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.000717</td>\n",
       "      <td>-0.000874</td>\n",
       "      <td>-0.000853</td>\n",
       "      <td>-0.001072</td>\n",
       "      <td>-0.001317</td>\n",
       "      <td>-0.001026</td>\n",
       "      <td>-0.000956</td>\n",
       "      <td>-0.001644</td>\n",
       "      <td>-0.001373</td>\n",
       "      <td>-0.001650</td>\n",
       "      <td>-0.002014</td>\n",
       "      <td>-0.001494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.578263</td>\n",
       "      <td>0.409697</td>\n",
       "      <td>0.333826</td>\n",
       "      <td>0.311585</td>\n",
       "      <td>0.436341</td>\n",
       "      <td>0.307559</td>\n",
       "      <td>0.484377</td>\n",
       "      <td>0.437992</td>\n",
       "      <td>0.308617</td>\n",
       "      <td>0.213233</td>\n",
       "      <td>0.298616</td>\n",
       "      <td>0.326533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  41124.000000  41124.000000  41124.000000  41124.000000  41124.000000   \n",
       "mean      -0.000223     -0.000178     -0.000256     -0.000174     -0.000182   \n",
       "std        0.015302      0.012878      0.011970      0.013568      0.015274   \n",
       "min       -0.279700     -0.239281     -0.168041     -0.231304     -0.296560   \n",
       "25%       -0.000717     -0.000874     -0.000853     -0.001072     -0.001317   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        0.578263      0.409697      0.333826      0.311585      0.436341   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  41124.000000  41124.000000  41124.000000  41124.000000  41124.000000   \n",
       "mean       0.000035      0.000066     -0.000040     -0.000103      0.000222   \n",
       "std        0.014069      0.017283      0.016889      0.014073      0.015388   \n",
       "min       -0.323304     -0.440936     -0.284944     -0.228971     -0.336297   \n",
       "25%       -0.001026     -0.000956     -0.001644     -0.001373     -0.001650   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        0.307559      0.484377      0.437992      0.308617      0.213233   \n",
       "\n",
       "                 10            11  \n",
       "count  41124.000000  41124.000000  \n",
       "mean       0.000322      0.000512  \n",
       "std        0.017246      0.018429  \n",
       "min       -0.351654     -0.439251  \n",
       "25%       -0.002014     -0.001494  \n",
       "50%        0.000000      0.000000  \n",
       "75%        0.000000      0.000000  \n",
       "max        0.298616      0.326533  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coefficients\n",
    "pd.DataFrame(clf.coef_).transpose().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0168028401906\n",
      "1\n",
      "0.0146872872289\n",
      "2\n",
      "0.0124015173621\n",
      "3\n",
      "0.0155870051551\n",
      "4\n",
      "0.0196478941737\n",
      "5\n",
      "0.017362124307\n",
      "6\n",
      "0.0192588269624\n",
      "7\n",
      "0.0246085011186\n",
      "8\n",
      "0.0178970917226\n",
      "9\n",
      "0.0222740978504\n",
      "10\n",
      "0.0259216029569\n",
      "11\n",
      "0.0270401711896\n"
     ]
    }
   ],
   "source": [
    "for i in range(12):\n",
    "    print i\n",
    "    print sum(np.absolute(clf.coef_[i])>=0.05) / 41124.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04212761, -0.32258107, -0.68226428, -0.30332332, -0.15669442,\n",
       "       -0.37625077,  0.35199577,  0.55810838, -0.08935162,  0.25299597,\n",
       "        0.45191995,  0.35757302])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_train = pd.DataFrame(clf.predict_proba(Xtrain))\n",
    "actual_train = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_train.to_csv('pred_train.csv')\n",
    "actual_train.to_csv('actual_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74645, 1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# =========== Scratch, Delete Later =========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-a4f5d6b87f70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "max(clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4899718663128869"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try only using active for developing a model\n",
    "Xtrain = hstack((Xtrain_pb, Xtrain_dm, Xtrain_appid, Xtrain_appida, Xtrain_category, Xtrain_categorya), format='csr')\n",
    "Xtest = hstack((Xtest_pb, Xtest_dm, Xtest_appid, Xtest_appida, Xtest_category, Xtest_categorya), format='csr')\n",
    "y = ga_train['group_enc']\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "features = Xtrain\n",
    "labels = y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=1)\n",
    "\n",
    "clf_device = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "clf_device.fit(X_train, y_train)\n",
    "\n",
    "pred_device = clf_device.predict_proba(X_test)\n",
    "\n",
    "log_loss(np.array(y_test), pred_device)\n",
    "\n",
    "# 2.47280834\n",
    "# 2.447608\n",
    "# 2.489972"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.0, 2.4899718663128869), (0.5, 2.4164753734715827), (0.1, 2.3378787435612702), (0.05, 2.3030158056680095), (0.01, 2.2825095875909676), (0.005, 2.2897505389247894)]\n"
     ]
    }
   ],
   "source": [
    "c_tuning = [1.0, 0.5, 0.1, 0.05, 0.01, 0.005]\n",
    "log_loss_scores = []\n",
    "\n",
    "for C in c_tuning:\n",
    "    clf_tuning = LogisticRegression(C=C, multi_class='multinomial', solver='lbfgs')\n",
    "    clf_tuning.fit(X_train, y_train)\n",
    "    pred = clf_tuning.predict_proba(X_test)\n",
    "    ll = log_loss(np.array(y_test), pred)\n",
    "    log_loss_scores.append((C, ll))\n",
    "print log_loss_scores\n",
    "\n",
    "# [(1.0, 2.4728083456221461), (0.5, 2.4086033178319126), (0.1, 2.309619176820513), (0.05, 2.2876211025012108), (0.01, 2.2835842878600849), (0.005, 2.2948924676044133)]\n",
    "# 2.28358\n",
    "# 2.28175\n",
    "# 2.282509"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74645, 131)\n",
      "(74645, 1599)\n",
      "\n",
      "(74645, 19238)\n",
      "(74645, 19238)\n",
      "\n",
      "(74645, 459)\n",
      "(74645, 459)\n"
     ]
    }
   ],
   "source": [
    "#Xtrain_pb, Xtrain_dm, Xtrain_appid, Xtrain_appida, Xtrain_category, Xtrain_categorya\n",
    "\n",
    "print Xtrain_pb.shape\n",
    "print Xtrain_dm.shape\n",
    "print ''\n",
    "print Xtrain_appid.shape\n",
    "print Xtrain_appida.shape\n",
    "print ''\n",
    "print Xtrain_category.shape\n",
    "print Xtrain_categorya.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112071, 131)\n",
      "(112071, 1599)\n",
      "\n",
      "(112071, 19238)\n",
      "(112071, 19238)\n",
      "\n",
      "(112071, 459)\n",
      "(112071, 459)\n"
     ]
    }
   ],
   "source": [
    "print Xtest_pb.shape\n",
    "print Xtest_dm.shape\n",
    "print ''\n",
    "print Xtest_appid.shape\n",
    "print Xtest_appida.shape\n",
    "print ''\n",
    "print Xtest_category.shape\n",
    "print Xtest_categorya.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
